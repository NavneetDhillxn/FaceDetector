{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b03c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH=os.path.join('data','images')\n",
    "number_images=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9816c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "  ret,frame=cap.read()\n",
    "  imgname=os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
    "  cv2.imwrite(imgname,frame)\n",
    "  cv2.imshow('frame',frame)\n",
    "  time.sleep(0.5)\n",
    "\n",
    "  if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=tf.data.Dataset.list_files('data/images/*.jpg',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd46aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(x):\n",
    "  byte_img=tf.io.read_file(x)\n",
    "  img=tf.io.decode_jpeg(byte_img)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b1e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    for file in os.listdir(os.path.join('data',folder,'images')):\n",
    "        filename=file.split('.')[0]+'.json'\n",
    "        existing_filepath=os.path.join('data','labels',filename)\n",
    "        \n",
    "        if os.path.exists(existing_filepath):\n",
    "            new_filepath=os.path.join('data',folder,'labels',filename)\n",
    "            os.replace(existing_filepath,new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor =alb.Compose([alb.RandomCrop(width=450,height=450),\n",
    "                       alb.HorizontalFlip(p=.5),\n",
    "                       alb.RandomBrightnessContrast(p=.2),\n",
    "                       alb.RandomGamma(p=.2),\n",
    "                       alb.RGBShift(p=.5),\n",
    "                       alb.VerticalFlip(p=.5),\n",
    "                       ],\n",
    "                      bbox_params=alb.BboxParams(format='albumentations',\n",
    "                                                label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(os.path.join('data','test','images','1c6c4762-1650-11ee-9a76-c8b29bfe0ea8.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data','test','labels','1c6c4762-1650-11ee-9a76-c8b29bfe0ea8.json'),'r') as f:\n",
    "    label=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e43fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord=[0,0,0,0]\n",
    "\n",
    "coord[0]=label['shapes'][0]['points'][0][0]\n",
    "coord[1]=label['shapes'][0]['points'][0][1]\n",
    "coord[2]=label['shapes'][0]['points'][1][0]\n",
    "coord[3]=label['shapes'][0]['points'][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord=np.divide(coord,[640,480,640,480])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a278e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented=augmentor(image=img,bboxes=[coord],class_labels=['face'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c96ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(augmented['image'],\n",
    "                tuple(np.multiply(augmented['bboxes'][0][:2],[450,450]).astype(int)),\n",
    "                tuple(np.multiply(augmented['bboxes'][0][2:],[450,450]).astype(int)),\n",
    "                (255,0,0),2\n",
    "            )\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa27a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['test','train','val']:\n",
    "    for image in os.listdir(f'data/{partition}/images'):\n",
    "        img=cv2.imread(f'data/{partition}/images/{image}')\n",
    "\n",
    "        coord=[0,0,0.0001,.0001]\n",
    "        label_path=f'data/{partition}/labels/{image.split(\".\")[0]}.json'\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path,'r') as f:\n",
    "                label=json.load(f)\n",
    "            \n",
    "            coord[0]=label['shapes'][0]['points'][0][0]\n",
    "            coord[1]=label['shapes'][0]['points'][0][1]\n",
    "            coord[2]=label['shapes'][0]['points'][1][0]\n",
    "            coord[3]=label['shapes'][0]['points'][1][1]\n",
    "\n",
    "            coord=list(np.divide(coord,[640,480,640,480]))\n",
    "\n",
    "        try:\n",
    "            for x in range(100):\n",
    "                augmented=augmentor(image=img,bboxes=[coord],class_labels=['face'])\n",
    "                cv2.imwrite(f'aug_data/{partition}/images/{image.split(\".\")[0]}{x}.jpg',augmented['image'])\n",
    "\n",
    "                annotations={}\n",
    "                annotations['image']=image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes'])==0:\n",
    "                        annotations['bbox']=[0,0,0,0]\n",
    "                        annotations['class']=0\n",
    "\n",
    "                    else :\n",
    "                        annotations['bbox']=augmented['bboxes'][0]\n",
    "                        annotations['class']=1\n",
    "                \n",
    "                else :\n",
    "                    annotations['bbox']=[0,0,0,0]\n",
    "                    annotations['class']=0\n",
    "\n",
    "                with open(f'aug_data/{partition}/labels/{image.split(\".\")[0]}{x}.json','w') as f:\n",
    "                    json.dump(annotations,f)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=tf.data.Dataset.list_files('aug_data/train/images/*.jpg',shuffle=False)\n",
    "train_images=train_images.map(load_image)\n",
    "train_images=train_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "train_images=train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images=tf.data.Dataset.list_files('aug_data/test/images/*.jpg',shuffle=False)\n",
    "test_images=test_images.map(load_image)\n",
    "test_images=test_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "test_images=test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f964ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images=tf.data.Dataset.list_files('aug_data/val/images/*.jpg',shuffle=False)\n",
    "val_images=val_images.map(load_image)\n",
    "val_images=val_images.map(lambda x: tf.image.resize(x,(120,120)))\n",
    "val_images=val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e115d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(),'r',encoding='utf-8') as f:\n",
    "        label=json.load(f)\n",
    "    \n",
    "    return [label['class']],label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=tf.data.Dataset.list_files('aug_data/train/labels/*.json',shuffle=False)\n",
    "train_labels=train_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.uint8,tf.float16]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4071185",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=tf.data.Dataset.list_files('aug_data/test/labels/*.json',shuffle=False)\n",
    "test_labels=test_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.uint8,tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a33b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=tf.data.Dataset.list_files('aug_data/val/labels/*.json',shuffle=False)\n",
    "val_labels=val_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.uint8,tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.data.Dataset.zip((train_images,train_labels))\n",
    "train=train.shuffle(200)\n",
    "train=train.batch(8)\n",
    "train=train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=tf.data.Dataset.zip((test_images,test_labels))\n",
    "test=test.shuffle(50)\n",
    "test=test.batch(8)\n",
    "test=test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "val=tf.data.Dataset.zip((val_images,val_labels))\n",
    "val=val.shuffle(50)\n",
    "val=val.batch(8)\n",
    "val=val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dafae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(ncols=4,figsize=(20,20))\n",
    "\n",
    "for i in range(4):\n",
    "    sample_image=res[0][i]\n",
    "    sample_coords=res[1][1][i]\n",
    "\n",
    "    cv2.rectangle(sample_image,\n",
    "                    tuple(np.multiply(sample_coords[:2],[120,120]).astype(int)),\n",
    "                    tuple(np.multiply(sample_coords[2:],[120,120]).astype(int)),\n",
    "                    (250,0,0),1\n",
    "                )\n",
    "    \n",
    "    ax[i].imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7004ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,Dense,Flatten,Add,GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdccf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "  input_layer=Input(shape=(120,120,3))\n",
    "  vgg=ResNet50(include_top=False)(input_layer)\n",
    "\n",
    "  f1=GlobalAveragePooling2D()(vgg)\n",
    "  class1=Dense(2048,activation='relu')(f1)\n",
    "  class2=Dense(1,activation='sigmoid')(class1)\n",
    "\n",
    "  f2=GlobalAveragePooling2D()(vgg)\n",
    "  reg1=Dense(2048,activation='relu')(f2)\n",
    "  reg2=Dense(4,activation='sigmoid')(reg1)\n",
    "\n",
    "  model=Model(inputs=input_layer,outputs=[class2,reg2])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a434337",
   "metadata": {},
   "outputs": [],
   "source": [
    "facetracker=build_model()\n",
    "facetracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true,yhat):\n",
    "    delta_cord=tf.reduce_sum(tf.square(y_true[:,:2]-yhat[:,:2]))\n",
    "\n",
    "    h_true=y_true[:,3]-y_true[:,1]\n",
    "    w_true=y_true[:,2]-y_true[:,0]\n",
    "\n",
    "    h_pred=yhat[:,3]-yhat[:,1]\n",
    "    w_pred=yhat[:,2]-yhat[:,0]\n",
    "    \n",
    "    delta_size=tf.reduce_sum(tf.square(w_true-w_pred)+tf.square(h_true-h_pred))\n",
    "\n",
    "    return delta_cord+delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679312c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.legacy.Adam(learning_rate=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss=tf.keras.losses.BinaryCrossentropy()\n",
    "regressloss=localization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[classloss,regressloss], optimizer='adam',loss_weights=[.5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceTracker(Model):\n",
    "    def __init__(self, eyetracker,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = eyetracker\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "\n",
    "    def train_step(self, batch, **kwargs):\n",
    "\n",
    "        X, y = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            classes, coords = self.model(X, training=True)\n",
    "\n",
    "            batch_classloss = self.closs(y[0], classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "\n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "\n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "\n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "\n",
    "    def test_step(self, batch, **kwargs):\n",
    "        X, y = batch\n",
    "\n",
    "        classes, coords = self.model(X, training=False)\n",
    "\n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "\n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "\n",
    "    def call(self, X, **kwargs):\n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0443f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=FaceTracker(facetracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt,classloss,regressloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train,validation_data=val,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04284477",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('aug_data/test/images/1c6c4762-1650-11ee-9a76-c8b29bfe0ea80.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b59d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.resize(img,(120,120))\n",
    "img=img/255\n",
    "pred=model.predict(np.expand_dims(img,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27208b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1][0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2802a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img,\n",
    "                tuple(np.multiply(pred[1][0][:2],[120,120]).astype(int)),\n",
    "                tuple(np.multiply(pred[1][0][2:],[120,120]).astype(int)),\n",
    "                (250,0,0),2)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d27ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model.fit(train,validation_data=val,epochs=2)\n",
    "    img=cv2.imread('aug_data/test/images/1c6c4762-1650-11ee-9a76-c8b29bfe0ea80.jpg')\n",
    "    img=cv2.resize(img,(120,120))\n",
    "    img=img/255\n",
    "    pred=model.predict(np.expand_dims(img,0))\n",
    "    cv2.rectangle(img,\n",
    "                    tuple(np.multiply(pred[1][0][:2],[120,120]).astype(int)),\n",
    "                    tuple(np.multiply(pred[1][0][2:],[120,120]).astype(int)),\n",
    "                    (250,0,0),2)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0141b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=joblib.load('faceDetect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "  ret,frame=cap.read()\n",
    "  \n",
    "  frame=cv2.resize(frame,(120,120))\n",
    "  frame=frame/255\n",
    "  pred=model.predict(np.expand_dims(frame,0))\n",
    "  frame=cv2.resize(frame,(480,480))\n",
    "  cv2.rectangle(frame,\n",
    "                    tuple(np.multiply(pred[1][0][:2],[480,480]).astype(int)),\n",
    "                    tuple(np.multiply(pred[1][0][2:],[480,480]).astype(int)),\n",
    "                    (0,0,250),1)\n",
    "                    \n",
    "  cv2.imshow('frame',frame)\n",
    "  if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e827e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
